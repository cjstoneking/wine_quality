{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for simplicity, have one hyperparameters object that contains all variables\n",
    "get_default_hyperparameters <- function(){\n",
    "    \n",
    "    hyperparameters <- list()\n",
    "    \n",
    "    #dataset-specific settings:\n",
    "    attr(hyperparameters, \"main_url\") <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/\"\n",
    "    attr(hyperparameters, \"files\")    <- c(\"winequality-red.csv\", \"winequality-white.csv\")\n",
    "    attr(hyperparameters, \"response_name\") <- \"quality\"\n",
    "    \n",
    "    \n",
    "    attr(hyperparameters, \"ensemble_K\")  <- 5\n",
    "    #number of folds of cross-validation for evaluating entire ensembles\n",
    "    attr(hyperparameters, \"top_level_repeats\") <- 10\n",
    "    #number of repeats to perform at top level (evaluating entire ensemble-forming strategy)\n",
    "    attr(hyperparameters, \"ensemble_size\") <- 2\n",
    "    attr(hyperparameters, \"n_attempts\") <- 3\n",
    "    attr(hyperparameters, \"single_model_K\") <- 10\n",
    "    #number of folds of cross-validation for finding single models\n",
    "    attr(hyperparameters, \"retest_predictors\") <- FALSE\n",
    "    attr(hyperparameters, \"weight_by_scores\") <- TRUE\n",
    "    return(hyperparameters)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function does all preprocessing (normalization etc.)\n",
    "#and defines new features by applying transformations\n",
    "preprocess <- function(data, response_name, hyperparameters=get_default_hyperparameters()){\n",
    "    \n",
    "    #separate into response and predictors\n",
    "    response <- data[[response_name]]\n",
    "    predictors <- data\n",
    "    predictors[[response_name]] <- NULL\n",
    "        \n",
    "    #z-score predictors\n",
    "    znorm <- function(x)  (x - mean(x))/ sd(x)\n",
    "    predictors <- apply(predictors, 2, znorm)\n",
    "    \n",
    "    #define new features\n",
    "    \n",
    "    predictors <- as.data.frame(predictors)\n",
    "    \n",
    "    #combine into single matrix again\n",
    "    data <- cbind(response, predictors)\n",
    "    colnames(data)[1] <- \"y\"\n",
    "    \n",
    "    return(data)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ensemble <- function(ensemble_models, data, scores=NULL, hyperparameters=get_default_hyperparameters(), verbose=FALSE){\n",
    "    \n",
    "    weight_by_scores <- attr(hyperparameters, \"weight_by_scores\")\n",
    "    \n",
    "    ensemble_size <- length(ensemble_models)\n",
    "    predictions <- vector(\"list\", ensemble_size)\n",
    "    for (n in 1:ensemble_size){\n",
    "        if(verbose){\n",
    "            print(paste(\"running model\", n, \"/\", ensemble_size, sep=\" \"))\n",
    "        }\n",
    "        predictions[[n]] <- predict(ensemble_models[[n]], newdata=data)\n",
    "    }\n",
    "    predictions_matrix <- t(Reduce(rbind, predictions))\n",
    "    \n",
    "    weights = rep(1/length(ensemble_models), length(ensemble_models))\n",
    "    if(length(scores)>0){\n",
    "        weights = -log(scores)\n",
    "        weights = weights/sum(weights)\n",
    "    }\n",
    "    else{\n",
    "        #assume NULL was passed for scores\n",
    "        weights = rep(1/length(ensemble_models), length(ensemble_models))\n",
    "    }\n",
    "    weighted_avg <- rep(0, nrow(data))\n",
    "    for (n in 1:ensemble_size){    \n",
    "        weighted_avg <- weighted_avg + weights[n]*predictions_matrix[,n]\n",
    "    }\n",
    "    \n",
    "    return(weighted_avg)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble <- function(ensemble_definition, data, hyperparameters=get_default_hyperparameters(), verbose=FALSE){\n",
    "    ensemble_size <- length(ensemble_definition)\n",
    "    ensemble_models <- vector(\"list\", ensemble_size)\n",
    "    n_comp <- attr(hyperparameters, \"pls_components\")\n",
    "    modele <- attr(hyperparameters, \"pls_model\")\n",
    "    \n",
    "    for (n in 1:ensemble_size){\n",
    "        if(verbose){\n",
    "            print(paste(\"training model\", n, \"/\", ensemble_size, sep=\" \"))\n",
    "        }\n",
    "        modelspec <- ensemble_definition[[n]]\n",
    "        train_data <- cbind(data$y, data[,modelspec])\n",
    "        colnames(train_data)[1] <- \"y\"\n",
    "        ensemble_models[[n]] <- lm(y ~ (.)^2, data=train_data)\n",
    "    }\n",
    "    \n",
    "    return(ensemble_models)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_ensemble <- function(data, hyperparameters=get_default_hyperparameters(), verbose=FALSE){\n",
    "    \n",
    "    \n",
    "    ensemble_size <- attr(hyperparameters, \"ensemble_size\")\n",
    "    ensemble = vector(\"list\", ensemble_size)\n",
    "    scores = rep(0, ensemble_size)\n",
    "    \n",
    "    for (n in 1:ensemble_size){\n",
    "    \n",
    "        if(verbose){\n",
    "            print(paste(\"finding model\", n, \"/\", ensemble_size, sep=\" \"))\n",
    "        }\n",
    "        outputs <- find_single_model(data, hyperparameters=hyperparameters, verbose=verbose)\n",
    "        scores[n] <- outputs[[1]]\n",
    "        ensemble[[n]] <- outputs[[2]]\n",
    "    }\n",
    "    return(list(scores, ensemble))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find a single model\n",
    "#to serve as part of an ensemble\n",
    "#return set of predictors used for that model\n",
    "find_single_model <- function(data, hyperparameters=get_default_hyperparameters(), verbose=FALSE){\n",
    "    \n",
    "    K <- attr(hyperparameters, \"single_model_K\")\n",
    "    CV_folds   <- get_CV_folds(nrow(data), K)\n",
    "    train_indices <- CV_folds[[1]]\n",
    "    test_indices <- CV_folds[[2]]\n",
    "    n_attempts <- attr(hyperparameters, \"n_attempts\")\n",
    "    n_comp <- attr(hyperparameters, \"pls_components\")\n",
    "    modele <- attr(hyperparameters, \"pls_model\")\n",
    "    retest <- attr(hyperparameters, \"retest_predictors\")\n",
    "    use_wvc <- FALSE#attr(hyperparameters, \"use_wvc\")\n",
    "    \n",
    "    response <- data$y\n",
    "    predictors <- data\n",
    "    predictors[[\"y\"]] <- NULL\n",
    "    \n",
    "    \n",
    "    predictor_set <- c()\n",
    "    best_predictor_set <- c()\n",
    "    tested_predictors <- c()\n",
    "    best_score <- Inf\n",
    "    \n",
    "    null_model_score <- 0\n",
    "    \n",
    "    for(n in 1:n_attempts){\n",
    "        \n",
    "        \n",
    "        current_predictor_set <- best_predictor_set\n",
    "        \n",
    "        #for the first iteration, run the empty model\n",
    "        #to get performance of intercept\n",
    "        #after first iteration, add predictors to model\n",
    "        if(n > 1){\n",
    "            all_predictors <- colnames(predictors)\n",
    "            unused_predictors <- c()\n",
    "            for(j in 1:length(all_predictors)){\n",
    "                p <- all_predictors[[j]]\n",
    "                if(!( p %in% current_predictor_set) && (retest || !(p %in% tested_predictors))){\n",
    "                    unused_predictors <- c(unused_predictors, p)\n",
    "                }\n",
    "            }\n",
    "            p <- sample(unused_predictors, 2, replace=FALSE)\n",
    "            current_predictor_set <- c(current_predictor_set, p)\n",
    "            tested_predictors <- p\n",
    "        }\n",
    "        if(verbose){\n",
    "            print(paste(\"Evaluating model:\", paste(current_predictor_set, sep=\" \", collapse=\", \"), sep=\" \"))\n",
    "        }\n",
    "        \n",
    "        oof_scores <- rep(0, K)\n",
    "        \n",
    "        \n",
    "        for(k in 1:K){\n",
    "            if(length(current_predictor_set)==0){\n",
    "                #empty model - just use mean as intercept\n",
    "                train_Y <- response[train_indices[[k]]]\n",
    "                test_Y  <- response[test_indices[[k]]] \n",
    "                prediction <- mean(train_Y)\n",
    "                oof_scores[k] <- mean(abs(test_Y - prediction))\n",
    "            }\n",
    "            else{\n",
    "                train_X <- predictors[train_indices[[k]],current_predictor_set]\n",
    "                test_X  <- predictors[test_indices[[k]],current_predictor_set]\n",
    "                train_Y <- response[train_indices[[k]]]\n",
    "                test_Y  <- response[test_indices[[k]]] \n",
    "                \n",
    "                train_data <- cbind(train_Y, train_X)\n",
    "                test_data <- cbind(test_Y, test_X)\n",
    "                colnames(train_data)[1] <- \"y\"\n",
    "                colnames(test_data)[1] <- \"y\"\n",
    "\n",
    "                model  <- lm(y ~ (.)^2, data=train_data)\n",
    "            \n",
    "                oof_scores[k] <- mean(abs(test_data$y- predict(model, newdata=test_data)))\n",
    "            }\n",
    "\n",
    "        }#end loop over folds\n",
    "        \n",
    "        if(length(current_predictor_set)==0){\n",
    "            null_model_score <- mean(oof_scores)\n",
    "        }\n",
    "        \n",
    "        \n",
    "        #if the model is an improvement over previous best, update it\n",
    "        final_score <- mean(oof_scores)\n",
    "        \n",
    "        if(final_score < best_score){\n",
    "            output_message = \"Keeping model\"\n",
    "            best_score <- final_score\n",
    "            best_predictor_set <- current_predictor_set\n",
    "        }\n",
    "        else{\n",
    "            output_message = \"Discarding model\"\n",
    "        }\n",
    "        if(verbose){\n",
    "            print(paste(\"Model score =\", final_score, sep=\" \"))\n",
    "            print(output_message)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    #return description of this model\n",
    "    #as a list of predictor names (strings)\n",
    "    return(list(best_score/null_model_score, best_predictor_set))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1 2\n",
      "[1] \"top-level CV fold  1\"\n",
      "[[1]]\n",
      "[1] \"alcohol\"              \"sulphates\"            \"total.sulfur.dioxide\"\n",
      "[4] \"file.number=1\"       \n",
      "\n",
      "[[2]]\n",
      "[1] \"residual.sugar\"   \"volatile.acidity\" \"fixed.acidity\"    \"chlorides\"       \n",
      "\n",
      "[1] 0.8654326 0.9152374\n",
      "[1] \"score = 0.60021809939634\"\n",
      "[1] \"top-level CV fold  2\"\n",
      "[[1]]\n",
      "[1] \"total.sulfur.dioxide\" \"sulphates\"            \"residual.sugar\"      \n",
      "[4] \"density\"             \n",
      "\n",
      "[[2]]\n",
      "[1] \"pH\"                  \"citric.acid\"         \"free.sulfur.dioxide\"\n",
      "[4] \"sulphates\"          \n",
      "\n",
      "[1] 0.8951830 0.9808707\n",
      "[1] \"score = 0.607297712538401\"\n",
      "[1] \"top-level CV fold  3\"\n",
      "[[1]]\n",
      "[1] \"sulphates\"            \"residual.sugar\"       \"total.sulfur.dioxide\"\n",
      "[4] \"chlorides\"           \n",
      "\n",
      "[[2]]\n",
      "[1] \"chlorides\"        \"file.number=1\"    \"volatile.acidity\" \"density\"         \n",
      "\n",
      "[1] 0.9352931 0.9128431\n",
      "[1] \"score = 0.626131561927111\"\n",
      "[1] \"top-level CV fold  4\"\n",
      "[[1]]\n",
      "[1] \"file.number=1\"       \"free.sulfur.dioxide\" \"fixed.acidity\"      \n",
      "[4] \"alcohol\"            \n",
      "\n",
      "[[2]]\n",
      "[1] \"density\"        \"residual.sugar\" \"file.number=1\"  \"alcohol\"       \n",
      "\n",
      "[1] 0.8667649 0.8844056\n",
      "[1] \"score = 0.599945679194636\"\n",
      "[1] \"top-level CV fold  5\"\n",
      "[[1]]\n",
      "[1] \"fixed.acidity\" \"alcohol\"       \"density\"       \"chlorides\"    \n",
      "\n",
      "[[2]]\n",
      "[1] \"residual.sugar\"      \"free.sulfur.dioxide\" \"citric.acid\"        \n",
      "[4] \"volatile.acidity\"   \n",
      "\n",
      "[1] 0.9026622 0.9340919\n",
      "[1] \"score = 0.604926954877024\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_or_download_data <- function (main_url, files){\n",
    "\n",
    "    for (i in 1:length(files)){\n",
    "        if(!file.exists(files[i])){\n",
    "            print(paste(\"Could not find\", files[i], \"- attempting to download\", sep=\" \" ))\n",
    "            download.file(paste(main_url, files[i],sep=\"\") , files[i], \"auto\", quiet = FALSE)\n",
    "        }\n",
    "    }\n",
    "    for (i in 1:length(files)){\n",
    "        if(!file.exists(files[i])){\n",
    "            print(paste(\"Could not find or download\", files[i], \"- training will fail\", sep=\" \" ))\n",
    "            return(0)\n",
    "        }\n",
    "    }\n",
    "    return(1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_CV_folds <- function(N, K){\n",
    "    train_indices <- vector(\"list\", K)\n",
    "    test_indices  <- vector(\"list\", K)\n",
    "    random_permutation <- sample(N, N, replace=FALSE)\n",
    "    for (i in 1:K){\n",
    "        start <- floor(N*(i-1)/K) + 1\n",
    "        stop  <- floor(N*i/K)\n",
    "        test_indices[[i]] <-  random_permutation[start:stop]\n",
    "        train_indices[[i]] <- random_permutation[-(start:stop)]\n",
    "    }\n",
    "    return(list(train_indices, test_indices))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script for evaluating different approaches\n",
    "evaluate_ensemble <- function(hyperparameters){\n",
    "\n",
    "    \n",
    "    verbose <- FALSE\n",
    "    \n",
    "    \n",
    "    \n",
    "    have_data <- find_or_download_data(main_url, files)\n",
    "    if(!have_data){\n",
    "        print(\"Could not find or download data - returning null\")\n",
    "        return(NULL)\n",
    "    }\n",
    "    else{\n",
    "        single_datasets <- vector(\"list\", length(files))\n",
    "        for (i in 1:length(files)){\n",
    "            single_datasets[[i]] <- read.csv(files[i], header=TRUE, sep=\";\")\n",
    "            single_datasets[[i]]$file.number <- i\n",
    "        }\n",
    "        data <- cbind(single_datasets)\n",
    "        data <- bind_rows(single_datasets)\n",
    "        #data = full dataset (merged across all files)\n",
    "        \n",
    "        #make one-hot encoding of file number\n",
    "        u <- unique(data$file.number)\n",
    "        print(u)\n",
    "        for (val in u[1:(length(u)-1)]){\n",
    "            data[paste(\"file.number=\",val,sep=\"\")] <- (data$file.number==val)*1.0\n",
    "        }\n",
    "        data$file.number <- NULL\n",
    "        \n",
    "        data <- preprocess(data, response_name)\n",
    "        \n",
    "        CV_indices <- get_CV_folds(nrow(data), K)\n",
    "        train_indices <- CV_indices[[1]]\n",
    "        test_indices  <- CV_indices[[2]]\n",
    "        \n",
    "        for (i in 1:K){\n",
    "            if(verbose){\n",
    "                print(paste('Top-level CV fold ', i, sep=' '))\n",
    "            }\n",
    "            #first step: find an ensemble of models\n",
    "            #by searching the space of possible models\n",
    "            #(this is the space of 2^P possible subsets of all predictors)\n",
    "            outputs <- find_ensemble(data[train_indices[[i]],])\n",
    "            scores <- outputs[[1]]\n",
    "            ensemble_definitions <- outputs[[2]]\n",
    "            if(verbose){\n",
    "                print('Model definitions:')\n",
    "                print(ensemble_definitions)\n",
    "                print('Scores:')\n",
    "                print(scores)\n",
    "            }\n",
    "            #now train the ensemble on the same data\n",
    "            ensemble_models <- train_ensemble(ensemble_definitions, data[train_indices[[i]],])\n",
    "            predictions <- run_ensemble(ensemble_models, data[test_indices[[i]],], scores, hyperparameters)\n",
    "            score <- mean(abs(predictions - data$y[test_indices[[i]]]))\n",
    "            print(paste(\"Ensemble score =\",score,sep=\" \"))\n",
    "            \n",
    "        }\n",
    "  \n",
    "    }\n",
    "    return(NULL)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top level code: define hyperparameters, run ensemble\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
